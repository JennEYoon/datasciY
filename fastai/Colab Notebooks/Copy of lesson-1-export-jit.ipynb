{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of lesson-1-export-jit.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/fastai/course-v3/blob/master/docs/production/lesson-1-export-jit.ipynb","timestamp":1560382216636}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9dj6_04sANB2","colab_type":"text"},"source":["# fast.ai lesson 1 - training on Notebook Instance and export to torch.jit model"]},{"cell_type":"code","metadata":{"id":"FmTwuSmuBVn8","colab_type":"code","colab":{}},"source":["!curl -s https://course/fast.ai/setup/colab | bash"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b7aZFj2pANB4","colab_type":"text"},"source":["## Overview\n","This notebook shows how to use the SageMaker Python SDK to train your fast.ai model on a SageMaker notebook instance then export it as a torch.jit model to be used for inference on AWS Lambda.\n","\n","## Set up the environment\n","\n","You will need a Jupyter notebook with the `boto3` and `fastai` libraries installed. You can do this with the command `pip install boto3 fastai`\n","\n","This notebook was created and tested on a single ml.p3.2xlarge notebook instance. \n"]},{"cell_type":"markdown","metadata":{"id":"Ii9h1bEpANB5","colab_type":"text"},"source":["## Train your model\n","\n","We are going to train a fast.ai model as per [Lesson 1 of the fast.ai MOOC course](https://course.fast.ai/videos/?lesson=1) locally on the SageMaker Notebook instance. We will then save the model weights and upload them to S3.\n","\n"]},{"cell_type":"code","metadata":{"id":"yC3zoySoANB6","colab_type":"code","colab":{}},"source":["%reload_ext autoreload\n","%autoreload 2\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"82RQx-IEANB-","colab_type":"code","colab":{}},"source":["import os\n","import io\n","import tarfile\n","\n","import PIL\n","\n","import boto3\n","\n","from fastai.vision import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYxEMuHmANCC","colab_type":"code","colab":{}},"source":["path = untar_data(URLs.PETS); path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LB1CbbNXANCE","colab_type":"code","colab":{}},"source":["path_anno = path/'annotations'\n","path_img = path/'images'\n","fnames = get_image_files(path_img)\n","np.random.seed(2)\n","pat = re.compile(r'/([^/]+)_\\d+.jpg$')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_R0CocSANCH","colab_type":"code","colab":{}},"source":["bs=64\n","img_size=299"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXygXyjZANCJ","colab_type":"code","colab":{}},"source":["data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(),\n","                                   size=img_size, bs=bs//2).normalize(imagenet_stats)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9P9boWGANCM","colab_type":"code","colab":{}},"source":["learn = cnn_learner(data, models.resnet50, metrics=error_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EcPGe5L9ANCO","colab_type":"code","colab":{}},"source":["learn.lr_find()\n","learn.recorder.plot()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1B-FuTQqANCU","colab_type":"code","colab":{}},"source":["learn.fit_one_cycle(8)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hZykMMtuANCX","colab_type":"code","colab":{}},"source":["learn.unfreeze()\n","learn.fit_one_cycle(3, max_lr=slice(1e-6,1e-4))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P2wwxAswANCb","colab_type":"text"},"source":["## Export model and upload to S3"]},{"cell_type":"markdown","metadata":{"id":"6RubGcvPANCc","colab_type":"text"},"source":["Now that we have trained our model we need to export it, create a tarball of the artefacts and upload to S3.\n"]},{"cell_type":"markdown","metadata":{"id":"_HEBlRQ-ANCd","colab_type":"text"},"source":["First we need to export the class names from the data object into a text file."]},{"cell_type":"code","metadata":{"id":"jDFPIMpDANCd","colab_type":"code","colab":{}},"source":["save_texts(path_img/'models/classes.txt', data.classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z0e07PC6ANCg","colab_type":"text"},"source":["Now we need to export the model in the [PyTorch TorchScript format](https://pytorch.org/docs/stable/jit.html) so we can load into an AWS Lambda function."]},{"cell_type":"code","metadata":{"id":"uYDqKq-IANCh","colab_type":"code","colab":{}},"source":["trace_input = torch.ones(1,3,img_size,img_size).cuda()\n","jit_model = torch.jit.trace(learn.model.float(), trace_input)\n","model_file='resnet50_jit.pth'\n","output_path = str(path_img/f'models/{model_file}')\n","torch.jit.save(jit_model, output_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lBxEovIdANCl","colab_type":"text"},"source":["Next step is to create a tarfile of the exported classes file and model weights."]},{"cell_type":"code","metadata":{"id":"O1zGDyr9ANCl","colab_type":"code","colab":{}},"source":["tar_file=path_img/'models/model.tar.gz'\n","classes_file='classes.txt'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uhqb6ZIdANCn","colab_type":"code","colab":{}},"source":["with tarfile.open(tar_file, 'w:gz') as f:\n","    f.add(path_img/f'models/{model_file}', arcname=model_file)\n","    f.add(path_img/f'models/{classes_file}', arcname=classes_file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yQClJM3cANCq","colab_type":"text"},"source":["Now we need to upload the model tarball to S3."]},{"cell_type":"code","metadata":{"id":"_S-XGu5xANCq","colab_type":"code","colab":{}},"source":["s3 = boto3.resource('s3')\n","s3.meta.client.upload_file(str(tar_file), 'REPLACE_WITH_YOUR_BUCKET_NAME', 'fastai-models/lesson1/model.tar.gz')"],"execution_count":0,"outputs":[]}]}