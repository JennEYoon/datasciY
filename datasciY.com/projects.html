<!DOCTYPE html>
<html lang="en-US">


<head>
<meta charset="UTF-8" />	
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<title>Projects-datasciY.com</title>

<meta name="description" content="Jennifer Yoon's Data Science Programming Portfolio." />
<meta name="keywords" content="data science, python, numpy, pandas, matplotlib, scipy, scikit-learn, machine learning, deep learning, AI, tensorflow, pytorch, keras, pydata, programming, coding, VBA, Excel, SQL, database" />
<link rel="stylesheet" href="http://datasciY.com/dsy.css">
<link rel="stylesheet" href="dsy.css">
</head>


<body>
<header><!-- Header, background image, purple. -->    
    <p></p>
    <h1>Projects</h1>
    <p class="tagline">datasciY.com</p>
    <p></p>
    <p></p>
    <p></p>

    <!-- Main navigation -->
    <ul class="nav-ul"> 
    <li class="nav-li"><a href="/about.html">About</a></li>
    <li class="nav-li"><a href="/blog.html">Blog</a></li> 
    <li class="nav-li"><a class="active" href="/projects.html">Projects</a></li>
    <li class="nav-li"><a href="/articles.html">Articles</a></li>
    <li class="nav-li"><a href="/general.html">General</a></li>
    </ul>
</header>


<section><!-- Main content. --> 

    <h3>Introduction</h3>
        <p>Welcome to my data science projects portfolio. </p>
        <ul>
        <li>Author: Jennifer Yoon</li>
        <li>Contact email: "datasciY.info@gmail.com"</li>
        <li>Resume: <a href="http://datasciY.com/assets/JenniferYOON-ds-resume.pdf">JenniferYoon-ds-resume-PDF</a></li>
        <li>GitHub Profile: <a href="https://github.com/JennEYoon">JennEYoon</a></li>    
        <li>Stack Overflow Profile: <a href="https://stackoverflow.com/users/4693491/jennifer-yoon?tab=profile">user:4693491, user name: Jennifer Yoon</a></li>
        </ul>

        <p>This projects portfolio is very much a work in progress. When the portfolio is full, my goal is to cover the full spectrum of data science process while using Python, SQL, Excel-VBA, Amazon Web Services (AWS) and Google Colaboratory (Colab). </p>
        <p>My main area of interest is in applying data science tools to bring value to the financial derivative securities industry, the financial risk management industry and the economic policy setting industry. I am also interested in visual deep learning as it is applied to brain segmentation image analysis (e.g., Janelia.org) and to geospatial intelligence analysis (e.g., NGA.org).</p>  
        <p>Some of the specific types of analyses I will be performing include: decision trees and random forests, principal component analysis (PCA), k-means clustering, sentiment analysis, natural language processing (NLP), linear regression, logistic regression, time-series, econometrics, big data cloud computing, deep-learning and convolutional neural networks (CNN).</p>
 

    <h3>Python Basics</h3>    
        

    <h4>File-IO demo</h4>
    <p>A demonstration of reading in a text file using 'rt' read text and 'rb' read binary methods. 
        For reverse order read and non-sequential read, 'rb' binary read is usually faster.  Relative address seek (from end of file and from current position) is only available for binary read method.   
    </p>
        <ul>       
        <li>Static view in browser: <a href="https://nbviewer.jupyter.org/github/JennEYoon/datasciY/blob/main/datasciY.com/projects/fileio/fileio-demo.ipynb"> via nbviewer</a> </li>
        <li>Executable notebook: <a href="https://colab.research.google.com/github/JennEYoon/datasciY/blob/main/datasciY.com/projects/fileio/fileio-demo.ipynb">open in colab</a>.</li>
        <li>View on Github: <a href="https://github.com/JennEYoon/datasciY/blob/main/datasciY.com/projects/fileio/fileio-demo.ipynb">fileio-demo.ipynb</a></li>
        <li>Download file from this site: <a href="./projects/fileio/fileio-demo.ipynb">fileio-demo</a>, <a href="./projects/fileio/demofile.txt">text file 1</a>, <a href="./projects/fileio/TheRaven-Poe.txt">text file 2</a> </li>    
        </ul>
    
        <p>Later, I will cover reading from JSON, CSV, Excel, and SQL formats.  I will also cover scraping data directly from websites.</p>

    <h4>Downloading Whole class, Coursera.org</h4>  
        <ul>
        <li>Date: September 16, 2020 </li>
        <li>Coursera whole class download instruction: <a href="./projects/coursera_dn/coursera_dn.md">markdown file</a></li>
        <li>folder-view jupyter image - to add</li>
        <li>local linux terminal image - to add</li>
        </ul>
        <p>While studying Andrew Ng's Deep Learning AI classes on Coursera.org, I needed a way to download the entire class at once, with all of the supporting images and data files.  Using the GUI to download files, I had to click and download each file one by one.  Some of the Jupyter notebooks have many supporting image files.  Large datasets can't be downloaded at all due to download size limit on the server.  Maybe Coursera will offer an easier download solution in the future.  But for now, "tar" and "cat" Linux commands work on Coursera's Linux server and on my computer's Linux terminal. (I use Windows Subsystem for Linux.)  It's important that "tar" and "cat" are default tools built into Linux, since I don't have the permission to install any new tools on Coursera's server.  This method may work for non-Coursera classes where you have access to a server-side Linux terminal or a Jupyter notebook with ! Linux shell command capability. </p>


    <h4>Adding Colab badge to Jupyter notebook</h4>    

        <ul>
            <li>Date: September 5, 2020</li>
            <li>Jupyter notebook: <a href="https://github.com/JennEYoon/datasciY/blob/main/example_rt.ipynb">example_rt.ipynb</a> from Github</li> 
            <li>Browser static view:  <a href="https://nbviewer.jupyter.org/github/JennEYoon/datasciY/blob/main/example_rt.ipynb">example_rt.ipynb</a> via nbviewer </li>
        </ul>
        <p>This is an example of a Jupyter notebook with "Open in Colab" and "Run in Colab" badges.  Google Colab is a free machine learning resource using the Jupyter notebook interface.  You can run deep learning models on GPU machines and lighter machine learning models on CPU machines. The badges open my example notebook stored on Github.com.  You can see the badge code by changing the cell format containing the badge to "raw".  Feel free to copy it into your own notebooks.  Change the href link to point to your own Github account and file path.</p>    
        <p>Example notebook shows <b>Matplotlib</b> plotting functions.  The first figure is an example of 3-dimensional projection of sign and cosign waves.  The second figure is a histogram with three overlapping data series combined into one image.  Alpha transparency is set to moderate opacity.  I am working on a separate demo of Matplotlib commands that clearly separates out the  <b>"plt" (Matlab like)</b> method from the <b>"ax" (object oriented)</b> method.  I found this area to be confusing at first, so perhaps other new users can benefit from my effort. </p>


    <h3>Using NumPy data arrays</h3>
        <p>Practice exercises using NumPy n-dimensional arrays.</p>

        <ul>
        <li><a href="http://datasciY.com/projects/numpy_ex1_jy.html">Numpy Exercise 1</a>  (html), &nbsp; <a href="https://github.com/JennEYoon/datasciY/blob/main/projects/numpy_ex1_jy.ipynb">GitHub</a></li>
        <li><a href="/projects/numpy_ex2.py">NumPy Exercise 2</a> (py), &nbsp; <a href="https://github.com/JennEYoon/datasciY/blob/main/projects/numpy_ex2.py">GitHub</a></li>
        </ul>


    <h3>Visualizing Interactive Charts with Dash and Plotly</h3>
        <ul>
        <li><a href="https://plot.ly/products/dash/">Dash from Plot.ly</a></li>
        <li><a href="https://plot.ly/d3-js-for-python-and-pandas-charts/"> Plotly for Python </a></li>
        </ul>
        <p>Dash is an interactive charting app for the web that can be built using Python. No JavaScript required.  Dash is built on top of the Plotly chart definitions.  Python developers can use many of Plotly's chart styles in their default mode to create beautiful, interactive charts.  Website visitors can zoom in or out of the chart, seeing details or a summary view.  Full customization is available via Plotly's open-source GitHub repo.</p>
        <p>Dash allows you to build a <strong>web app</strong> with your customized sliders, radio buttons, text input, and user-selected data sorting and filtering.  While Plotly has <strong>built-in default chart types</strong> with zoom, pan, expand/collapse and data filtering already included. </p>

        <p>More to follow. </p>
        <p></p>    

    
    <h3>Titanic Project (ML) DRAFT</h3>
        <p>Passenger information from the Titanic ship is a common data set used in machine learning (ML). Here I use Python and data science libraries to find patterns in the data and build a prediction model. Then I use various visualization libraries to create pretty figures.</p>

        <ul>
        <li>View html version of Jupyter notebook: <a href="http://datasciY.com/projects/titanic/titanic-part1-v4.html">Titanic-NB-HTML</a></li>
        <li>Download from GitHub, full Jupyter notebook: <a href="https://github.com/JennEYoon/datasciY/blob/main/projects/titanic/titanic-part1-v4.ipynb">GitHub Titanic-NB</a></li>
        <li>Tags: exploratory data analysis (EDA), machine learning (ML), graphics,  logistic regression </li>
        <li>Data: https://www.kaggle.com/c/titanic/data: <a href="https://www.kaggle.com/c/titanic/data">Kaggle Titanic data.</a></li>
        <li>Reference: Rossant, Cyrille, <em>Ipython Interactive Computing and Visualization Cookbook</em>, 2nd ed., Packt Publishing 2018, pp. 299-304.</li>
        </ul>

        <p>To be continued later.</p>
        <p></p>


    <h3>Bias-Variance Tradeoff at a Glance</h3>
        <p>A picture showing conceptually the bias-variance tradeoff in machine learning. </p>
        <p><img height="auto" width="400" src="http://datasciY.com/projects/bias-var-tradeoff.png" alt="bias-variance tradeoff" /></p>

        <p>A test result with a bias problem refers to a case where the true mean was totally missed by the machine learning model.  See bottom-left target in image above.  A test result with a variance problem refers to a case where the machine learning predictions are too widely distributed to provide a meaningful indicator to the decision maker.  See top-right target.  
        In most modeling situations, there is a tradeoff between hitting the true mean and reducing the variability around that true mean.  Generally, it is not possible to maximize both.  See top-left target.  But it is possible to achieve poor results in both parameters from a poor model parameter selection.  See bottom-right target.  </p>
        <p>Source: Pierian Data, Udemy.com., Python Machine Learning Data Science Boot Camp
        <ul>
        <li><a href="https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/">Udemy class link</a></li>     
        <li>Image from <a href="https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/learn/v4/t/lecture/5733420?start=0">section 16 link</a>. Login to access.</li>
        </ul></p>


<p> &nbsp; </p>
</section><!-- End main content -->


<section><!-- DRAFTs, WIPs section start -->

<!-- Template Paragraph 
    <h3>DRAFT - Title 1</h3>
    <ul>
    <li>item 1</li>
    <li>item 2</li>
    <li>item 3</li>
    </ul>

    <ol>
    <li>item 1</li>
    <li>item 2</li>
    <li>item 3</li>
    </ol>
    <p>Lorem ipsum, dolor sit amet consectetur adipisicing elit. Assumenda, velit.</p>
    -->


    <!-- work in process  
    <h3>Tools - MyBinder and Google Colab for Hosting Jupyter Notebooks</h3>
        <p>WIP</p>
        <p>
        Pros & Cons
        Link to Binder built Docker image, 
        Link to conda env.yml
        Link to Matplotlib 3D plots example notebook
        Writing about saving edits on MyBinder.org and download locally, upload to Github to commit new version.
        Also link to CoLab, running Jupyter notebook from binder docker image. 
        </p>
    -->


    <!-- to do soon, add class obj materials, then post.      
    <h3>Python Basics</h3>
    <ul>
    <li>Functions - Pass functions as inputs to another function.
        <a href="/projects/function_ex1.py"> Function Exercise 1</a>
    </li>
    <li>Functions - *arg, **kwargs, defaults, and variables order. To do.
        <br /> 
        Reference: <a href="https://www.geeksforgeeks.org/args-kwargs-python">www.geeksforgeeks.org</a>"
    </li>
    <li>Class Objects - Spaceship Class, Asteroid Class.
        <a href=""></a>  To do. 
    
    <li>To do -- Pandas as Class Objects, NumPy as Class Objects.</li> 
    </ul>
    -->

<!-- to do soon  
    <h3>Sorting, Recursion and Big-O Math</h3>
        <p>Algorithm efficiency is studied using the Big-O math.  Generally an order of log(n) is preferred over an order of n*log(n), n**3, or n!.  The best algorithm has an order of n, <strong>O(n)</strong>, but this is rarely achieved.  An O(n) means that as the number of inputs grows, the time to execute grows linearly.  In my sorting algorithm, I use a binary tree with a central pivot point and recursive function calls to itself.  I use this algorithm to study Big-O math.  </p>
        
        <p>More to follow. </p>
        <p></p>    
        -->    

<!-- Level 2: Work in Progress Section ------------------------
    <h3>Visualizing 3D Volatility Surface Data with Matplotlib</h3>
    <p>To be added - WIP</p>

    <h3>Visualizing Energy Trading Data with Bokeh</h3>
    <p>To be added.</p>
    <p></p>

    <h3>Visualizing Economics Data with Tableau</h3>    
    <p>Link to Hans TED talk movie - to be added.</p>
    <p>Content to be added.</p>

    <h3>Amazon Lambda (AWS)</h3>
    <p>Sometimes it is really helpful to host a short, executable python code on a public web server. You may have a client with whom you wish to share an idea or a methodology. It may not be enough to show a static html page. Amazon's Lambda makes that easy to do. You can customize installed python libraries with "layers."</p>
    <p>I will post a demo using the Ubuntu Linux OS base machine and a Jupyter notebook running Python 3, and import NumPy, Pandas, Matplotlib, and Scikit-Learn libraries. I will also repeat the demo with a Windows 10 base machine for the 50% of population who uses a Windows computer.</p>
    <p>To be added.</p>
    <p></p>
    -->

<!-- Level 3: Draft until ready to finish ------------------------------ 
    <h3>When do you know you have sufficient samples from a streaming data source?</h3>

    <h4 style="color:navy; margin-left: 16px;">Answer: "It depends on the stability of your mean and standard deviation. By using the Central Limit Theorem, you can calculate the probability that you have sufficient data."</h4>

    <ul><li>Date: June 1, 2019</li></ul>
    <p>I went to an <a href="https://www.ntconcepts.com/">NT Concepts</a> talk this week, and an audience member asked a question, <strong>"When you are using a streaming data source, when do you know you have enough data?"</strong> I provided an audience answered to this question. I think the questioner was asking when can we have a reasonably high level of confidence that the sample data we are getting from the streaming data source is a good representation of the true population data. My answer was that, <strong>"From a statistics point of view, it depends on the stability of the sampled mean and sampled standard deviation over time. And I don't know the formula off the top of my head, but due to the Central Limit Theorem, there IS a formula that will allow one to calculate the <strong>probability</strong> that the streaming sampled data is [not representative of the true underlying data]"</strong>. (That is, the streaming data you have collected so far is <strong>NOT</strong> representative of the true population, and you need to collect more samples.) I forgot to mention that the number of observations and number of features you are using also matters, as these influence the degrees of freedom you have in the statistical calculation. And that my emphasis on the stability of mean and standard deviation over time was an indirect reference to stationarity and independence of samples. </p>

    <p>In summary, this question seems to come straight out of the <Strong>Central Limit Theorem</Strong>. Given the sample mean, sample standard deviation, independence, and stability of volatility -- the probability of the sampled mean approaching the true population mean <strong>can</strong> be estimated. (This is usually stated as the sampled mean approaching the true mean of the "Gaussian" probability density function, or some other named probability density functions, such as binominal, log-normal, exponential, etc.). I tried to follow up with the questioner, but the email address she gave me had an error. Anyway, I thought it might make a good post. So I will explore it further and write a post about it with real-world streaming data.</p>

    <p>To be continued later.</p>
    <p></p>
    -->

</section><!-- DRAFTs section end -->



<footer>    
    <p>Contact: "datasciY.info@gmail.com"  <br />
    Copyright &copy; 2018 - 2020 by Jennifer Yoon  <br />
    All rights reserved.</p>
</footer>


</body>
</html>
